{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g63g7IIxrlgp"
      },
      "source": [
        "#Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wObPH0rI5zor"
      },
      "outputs": [],
      "source": [
        "!pip install langchain --upgrade\n",
        "!pip install openai\n",
        "!pip install faiss-gpu\n",
        "!pip install tiktoken\n",
        "!pip install sentence_transformers\n",
        "!pip install wolframalpha\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSSPjJk6rgdE",
        "outputId": "82c567ce-1f57-4e6d-e617-116789e4b791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.agents import create_pandas_dataframe_agent\n",
        "from langchain.chains import RetrievalQAWithSourcesChain, LLMMathChain, LLMChain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents.agent_types import AgentType\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain import HuggingFaceHub, HuggingFacePipeline\n",
        "from transformers import T5Tokenizer\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import NLTKTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.utilities.wolfram_alpha import WolframAlphaAPIWrapper\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = ''\n",
        "os.environ[\"WOLFRAM_ALPHA_APPID\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLDT4cC5u3lD"
      },
      "source": [
        "#Create Docstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2-MANqHuF1-"
      },
      "outputs": [],
      "source": [
        "repo_path = './docs/'\n",
        "document_files = os.listdir(repo_path)\n",
        "\n",
        "def convert_path_to_doc_url(doc):\n",
        "  # Convert from relative path to actual document url\n",
        "  return './docs/'+doc\n",
        "\n",
        "text_splitter = CharacterTextSplitter(separator = \"\\n\",chunk_size = 256,chunk_overlap  = 20,length_function = len)\n",
        "\n",
        "documents = []\n",
        "for text_file in document_files:\n",
        "  if text_file.find('.txt') > -1:\n",
        "    content = open(repo_path+text_file, \"r\").read()\n",
        "    split_texts = text_splitter.split_text(content)\n",
        "    for text in split_texts:\n",
        "      text = text.replace('\\n',' \\n ')\n",
        "      documents.append(Document(page_content=text,metadata={\"source\": convert_path_to_doc_url(text_file)}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvke4Drpz1lb",
        "outputId": "cf924a68-f96e-460b-e331-9e686796372e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='© 2022 Cognizant  \\n Confidential or Trade Secret  \\n                           Leave Policy - India                                   Page 8 of 11  \\n    \\n •  \\n Associates Travelling on International Assignments with Payroll Transfer from / to India', metadata={'source': './docs/leave-policy_feb22_8.txt'})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IbIpnlscrq7u"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(deployment='text-embedding-ada-002',model=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mJUCGCU4v7v9"
      },
      "outputs": [],
      "source": [
        "vector_store.save_local('./Data_store/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HF5ofB_Y4AZH"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XensRLR2wFXK",
        "outputId": "ff704d1c-40ee-4114-8b07-3cb8f3089211"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nif os.path.exists(\\'./Data_store/\\'):\\n  vector_store = FAISS.load_local(\\n      \\'./Data_store/\\',\\n      embeddings\\n  )\\nelse:\\n  print(f\"Missing files. Upload index.faiss and index.pkl files to Data Store directory first\")\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "if os.path.exists('./Data_store/'):\n",
        "  vector_store = FAISS.load_local(\n",
        "      './Data_store/',\n",
        "      embeddings\n",
        "  )\n",
        "else:\n",
        "  print(f\"Missing files. Upload index.faiss and index.pkl files to Data Store directory first\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-SIxSGD1jiH"
      },
      "source": [
        "#Setup Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Ft9aXT1jRQ"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "system_template=\"\"\"Given the below document and a question, create a final answer with references (\"SOURCES\").\n",
        "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
        "ALWAYS return a \"SOURCES\" part in your answer.\n",
        "\n",
        "=========\n",
        "{summaries}\n",
        "=========\n",
        "\"\"\"\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "sW1Ggws1F8Mc",
        "outputId": "24dc35fc-5c2d-405c-d752-b051db2dcb78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'System: Given the below document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\n=========\\nWho was the father of Mary Ball Washington?\\n=========\\n\\nHuman: Who was the father of Mary Ball Washington?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "prompt.format(summaries = \"Who was the father of Mary Ball Washington?\",question = 'Who was the father of Mary Ball Washington?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GaNaMk2wr8W"
      },
      "source": [
        "#Setup LLM Model for QA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quTuGL6q0T3F"
      },
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(deployment_name=\"chatgpt\",model_name=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi8EwsT2wouA"
      },
      "outputs": [],
      "source": [
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "QAChain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RrZ1bpnDNru",
        "outputId": "2a7512b4-6cc6-4b07-836e-00f12f879793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'How Many Years are required to become FTE?',\n",
              " 'answer': '(2) years',\n",
              " 'sources': '',\n",
              " 'source_documents': [Document(page_content='(2) years.  \\n •  \\n Once the said period of two (2) years is attained on part time, Associates need to be converted  \\n to FTE. If part time option is requested for, beyond two (2) years, exception approval from BU  \\n Head (VP+) and India HR Head will be sought.  \\n •', metadata={'source': './docs/part-time-india_2.txt'}),\n",
              "  Document(page_content='To be eligible for this leave, the Associate must have spent at least two consecutive years of  \\n service with the Company. The Company may determine the number of Associates who shall  \\n be given this leave annually in accordance with work requirements.', metadata={'source': './docs/international-relocation-policy-dec-2022_66.txt'}),\n",
              "  Document(page_content='return to their Home Country prior to completion of four (4) months, then the Associate’s  \\n manager must inform Human Resources and provide a business justification for the Associate’s', metadata={'source': './docs/international-relocation-policy-dec-2022_133.txt'}),\n",
              "  Document(page_content='spends five consecutive years in the service of the Company. The Company may grant the  \\n Associate a part of his annual leave according to the period of year he spent working for the  \\n Company.', metadata={'source': './docs/international-relocation-policy-dec-2022_64.txt'})]}"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "QAChain('How Many Years are required to become FTE?')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}